{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aea2287-90ee-4162-bc69-345e8a7c5f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    " Created on 2021/4/19 11:47\n",
    " Filename   : spider_image_baidu.py\n",
    " Author     : Taosy\n",
    " Zhihu      : https://www.zhihu.com/people/1105936347\n",
    " Github     : https://github.com/AFei19911012\n",
    " Description: Spider - get images from baidu\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_images_from_baidu(keyword, page_num, save_dir):\n",
    "    # UA 伪装：当前爬取信息伪装成浏览器\n",
    "    # 将 User-Agent 封装到一个字典中\n",
    "    # 【（网页右键 → 审查元素）或者 F12】 → 【Network】 → 【Ctrl+R】 → 左边选一项，右边在 【Response Hearders】 里查找\n",
    "    # header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'}\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.67'}\n",
    "    # Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.67\n",
    "    # 请求的 url\n",
    "    url = 'https://image.baidu.com/search/acjson?'\n",
    "    n = 0\n",
    "    epoch = 1\n",
    "    total = 0\n",
    "    for pn in range(0, 30 * page_num, 30):\n",
    "        # 请求参数\n",
    "        time.sleep(random.randint(0, 10) / 10.0)\n",
    "\n",
    "        param = {'tn': 'resultjson_com',\n",
    "                 # 'logid': '7603311155072595725',\n",
    "                 'ipn': 'rj',\n",
    "                 'ct': 201326592,\n",
    "                 'is': '',\n",
    "                 'fp': 'result',\n",
    "                 'queryWord': keyword,\n",
    "                 'cl': 2,\n",
    "                 'lm': -1,\n",
    "                 'ie': 'utf-8',\n",
    "                 'oe': 'utf-8',\n",
    "                 'adpicid': '',\n",
    "                 'st': -1,\n",
    "                 'z': '',\n",
    "                 'ic': '',\n",
    "                 'hd': '',\n",
    "                 'latest': '',\n",
    "                 'copyright': '',\n",
    "                 'word': keyword,\n",
    "                 's': '',\n",
    "                 'se': '',\n",
    "                 'tab': '',\n",
    "                 'width': '',\n",
    "                 'height': '',\n",
    "                 'face': 0,\n",
    "                 'istype': 2,\n",
    "                 'qc': '',\n",
    "                 'nc': '1',\n",
    "                 'fr': '',\n",
    "                 'expermode': '',\n",
    "                 'force': '',\n",
    "                 'cg': '',    # 这个参数没公开，但是不可少\n",
    "                 'pn': pn,    # 显示：30-60-90\n",
    "                 'rn': '30',  # 每页显示 30 条\n",
    "                 'gsm': '1e',\n",
    "                 '1618827096642': ''\n",
    "                 }\n",
    "        request = requests.get(url=url, headers=header, params=param)\n",
    "        if request.status_code == 200:\n",
    "            print('Request success.')\n",
    "        request.encoding = 'utf-8'\n",
    "        # 正则方式提取图片链接\n",
    "        html = request.text\n",
    "        image_url_list = re.findall('\"thumbURL\":\"(.*?)\",', html, re.S)\n",
    "        print(f\"第{epoch}次爬取图片数量：\", len(image_url_list))\n",
    "        epoch += 1\n",
    "        total += len(image_url_list)\n",
    "        # # 换一种方式\n",
    "        # request_dict = request.json()\n",
    "        # info_list = request_dict['data']\n",
    "        # # 看它的值最后多了一个，删除掉\n",
    "        # info_list.pop()\n",
    "        # image_url_list = []\n",
    "        # for info in info_list:\n",
    "        #     image_url_list.append(info['thumbURL'])\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        for image_url in tqdm(image_url_list):\n",
    "            # time.sleep(0.2)\n",
    "            time.sleep(random.randint(0, 10) / 10.0)\n",
    "            \n",
    "            image_data = requests.get(url=image_url, headers=header).content\n",
    "            ct = time.time()\n",
    "            hm = str(int((ct - int(ct))*1000))\n",
    "            date = str(time.strftime(r'%H%M%S'))\n",
    "            with open(os.path.join(save_dir, f'{date+hm}.jpg'), 'wb') as fp:\n",
    "                fp.write(image_data)\n",
    "            n = n + 1\n",
    "    print(f'共抓取图片{n}张')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    keyword = '挖掘 航拍'\n",
    "    save_dir = 'E:/puzhou_train/zha_tu_che/images_from_baidu2/'\n",
    "    page_num = 10\n",
    "    get_images_from_baidu(keyword, page_num, save_dir)\n",
    "    print('Get images finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e260f52-f4f7-422f-84d6-f8b31ab1a1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
